{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "S1xGIOEP5qpT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxWv-36S4Na3"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CNFbwXgXFBEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sms-spam data\n",
        "data = pd.read_csv('sample_data/spam.csv', encoding = 'latin-1')\n",
        "data = data.iloc[:, :2]\n",
        "data.columns = ['label', 'text']"
      ],
      "metadata": {
        "id": "Qy842tH25dxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "data['label'] = data['label'].apply(lambda x: 1 if x == 'spam' else 0)"
      ],
      "metadata": {
        "id": "iVKbu48U5yyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into 2 sets: Count and tf-idf\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "M93jVcp6JuQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution and Description"
      ],
      "metadata": {
        "id": "VBj1bcUf9TFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the distribution of the target classes\n",
        "plt.hist(data['label'], bins=2, width=.2, align='right')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks([.35, .85], ['ham', 'spam'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "-2g1_ZjG9VGf",
        "outputId": "d71e9aed-36a6-4cec-a33d-6710e2c9eb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset) contains over 5000 SMS messages which are either spam or \"ham\" as shown in the distribution above. Messages that are \"ham\" are simply not spam. The model should be able to predict which messages are spam and which are \"ham\" or not spam based on the message. It should be able to analyze frequent words that appear across spam messages and use that to identify new spam messages."
      ],
      "metadata": {
        "id": "dpCebSbE_v_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequential Model"
      ],
      "metadata": {
        "id": "joLJzHk25gr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize and pad the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Train and test\n",
        "X_train = tokenizer.texts_to_sequences(train_data['text'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "max_length = max(len(x) for x in X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n",
        "\n",
        "y_train = train_data['label'].values\n",
        "y_test = test_data['label'].values\n",
        "\n",
        "# Define the sequential model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 16, input_length=max_length),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=20, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "zw728o255fiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e84cd72-f6d4-41a7-e9d7-11495ec8e6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "126/126 [==============================] - 2s 5ms/step - loss: 0.5303 - accuracy: 0.8659 - val_loss: 0.3954 - val_accuracy: 0.8565\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8671 - val_loss: 0.3703 - val_accuracy: 0.8565\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.3354 - accuracy: 0.8671 - val_loss: 0.3449 - val_accuracy: 0.8565\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8671 - val_loss: 0.2936 - val_accuracy: 0.8565\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.2265 - accuracy: 0.8838 - val_loss: 0.2109 - val_accuracy: 0.9081\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9484 - val_loss: 0.1441 - val_accuracy: 0.9574\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9766 - val_loss: 0.1098 - val_accuracy: 0.9641\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9838 - val_loss: 0.0909 - val_accuracy: 0.9664\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 1s 5ms/step - loss: 0.0467 - accuracy: 0.9880 - val_loss: 0.0808 - val_accuracy: 0.9686\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.0772 - val_accuracy: 0.9686\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9910 - val_loss: 0.0731 - val_accuracy: 0.9686\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.0749 - val_accuracy: 0.9686\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.0645 - val_accuracy: 0.9776\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0690 - val_accuracy: 0.9753\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.0661 - val_accuracy: 0.9753\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0669 - val_accuracy: 0.9753\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0651 - val_accuracy: 0.9776\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.0686 - val_accuracy: 0.9776\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0669 - val_accuracy: 0.9776\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 1s 6ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0687 - val_accuracy: 0.9776\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9821\n",
            "Test accuracy: 0.9820627570152283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "dkzbiQFxE06h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the RNN model\n",
        "model_rnn = Sequential([\n",
        "    Embedding(vocab_size, 16, input_length=max_length),\n",
        "    SimpleRNN(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Modify learning rate\n",
        "optimizer = Adam(learning_rate=.0001)\n",
        "\n",
        "# Compile and train the model\n",
        "model_rnn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model_rnn.fit(X_train, y_train, epochs=20, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model_rnn.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy (RNN): {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVPJzhsCE5xF",
        "outputId": "d689fe87-0c30-4953-fd53-433b59d58199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "126/126 [==============================] - 6s 32ms/step - loss: 0.5063 - accuracy: 0.8340 - val_loss: 0.4236 - val_accuracy: 0.8565\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3983 - accuracy: 0.8671 - val_loss: 0.4114 - val_accuracy: 0.8565\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 5s 43ms/step - loss: 0.3925 - accuracy: 0.8671 - val_loss: 0.4114 - val_accuracy: 0.8565\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4115 - val_accuracy: 0.8565\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4119 - val_accuracy: 0.8565\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4118 - val_accuracy: 0.8565\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.3919 - accuracy: 0.8671 - val_loss: 0.4116 - val_accuracy: 0.8565\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4115 - val_accuracy: 0.8565\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4118 - val_accuracy: 0.8565\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4117 - val_accuracy: 0.8565\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 4s 31ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4121 - val_accuracy: 0.8565\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4117 - val_accuracy: 0.8565\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4120 - val_accuracy: 0.8565\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 4s 31ms/step - loss: 0.3921 - accuracy: 0.8671 - val_loss: 0.4119 - val_accuracy: 0.8565\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 6s 44ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4115 - val_accuracy: 0.8565\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 6s 45ms/step - loss: 0.3919 - accuracy: 0.8671 - val_loss: 0.4120 - val_accuracy: 0.8565\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3922 - accuracy: 0.8671 - val_loss: 0.4122 - val_accuracy: 0.8565\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4115 - val_accuracy: 0.8565\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3920 - accuracy: 0.8671 - val_loss: 0.4115 - val_accuracy: 0.8565\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3921 - accuracy: 0.8671 - val_loss: 0.4118 - val_accuracy: 0.8565\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8655\n",
            "Test accuracy (RNN): 0.865470826625824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GloVe embedding"
      ],
      "metadata": {
        "id": "pv_bf4ZuHmzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load 100D GloVe embeddings\n",
        "glove_file_path = 'sample_data/glove.6B.100d.txt'\n",
        "embeddings_index = {}\n",
        "with open(glove_file_path, encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "# Create the embedding matrix\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "mQLMgB2IHmOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model with GloVe embeddings\n",
        "model_glove = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length, weights=[embedding_matrix], trainable=False),\n",
        "    SimpleRNN(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_glove.fit(X_train, y_train, epochs=20, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model_glove.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy (GloVe): {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjmUBQDDJJBu",
        "outputId": "5b42ef94-3e12-4bc2-b8a7-cbef577db823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "126/126 [==============================] - 5s 28ms/step - loss: 0.4335 - accuracy: 0.8070 - val_loss: 0.3601 - val_accuracy: 0.8565\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.3483 - accuracy: 0.8671 - val_loss: 0.3502 - val_accuracy: 0.8565\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3214 - accuracy: 0.8621 - val_loss: 0.3542 - val_accuracy: 0.8565\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3053 - accuracy: 0.8659 - val_loss: 0.4405 - val_accuracy: 0.8565\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3933 - accuracy: 0.8669 - val_loss: 0.4178 - val_accuracy: 0.8565\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.3900 - accuracy: 0.8669 - val_loss: 0.4011 - val_accuracy: 0.8565\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3849 - accuracy: 0.8669 - val_loss: 0.3994 - val_accuracy: 0.8565\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3637 - accuracy: 0.8646 - val_loss: 0.3300 - val_accuracy: 0.8386\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.3687 - accuracy: 0.8549 - val_loss: 0.4115 - val_accuracy: 0.8565\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.3930 - accuracy: 0.8669 - val_loss: 0.4116 - val_accuracy: 0.8565\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3931 - accuracy: 0.8669 - val_loss: 0.4139 - val_accuracy: 0.8565\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3923 - accuracy: 0.8669 - val_loss: 0.4121 - val_accuracy: 0.8565\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 4s 36ms/step - loss: 0.3925 - accuracy: 0.8671 - val_loss: 0.4113 - val_accuracy: 0.8565\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3930 - accuracy: 0.8671 - val_loss: 0.4114 - val_accuracy: 0.8565\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3925 - accuracy: 0.8671 - val_loss: 0.4131 - val_accuracy: 0.8565\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3935 - accuracy: 0.8671 - val_loss: 0.4168 - val_accuracy: 0.8565\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.3933 - accuracy: 0.8671 - val_loss: 0.4157 - val_accuracy: 0.8565\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.3927 - accuracy: 0.8671 - val_loss: 0.4174 - val_accuracy: 0.8565\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.3930 - accuracy: 0.8671 - val_loss: 0.4122 - val_accuracy: 0.8565\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 4s 28ms/step - loss: 0.3917 - accuracy: 0.8671 - val_loss: 0.4178 - val_accuracy: 0.8565\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.4009 - accuracy: 0.8637\n",
            "Test accuracy (GloVe): 0.8636771440505981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "kYIypz6LKycZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential\n",
        "_, seq_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# SimpleRNN\n",
        "_, rnn_accuracy = model_rnn.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# SimpleRNN with GloVe\n",
        "_, glove_accuracy = model_glove.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Print the accuracy scores for each model\n",
        "print(f\"Test accuracy (Sequential): {seq_accuracy:.2f}\")\n",
        "print(f\"Test accuracy (SimpleRNN): {rnn_accuracy:.2f}\")\n",
        "print(f\"Test accuracy (SimpleRNN with GloVe embeddings): {glove_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5hmNHeqKz3e",
        "outputId": "50891279-f250-447c-eada-67d6d620407a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy (Sequential): 0.98\n",
            "Test accuracy (SimpleRNN): 0.87\n",
            "Test accuracy (SimpleRNN with GloVe embeddings): 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary & Analysis\n",
        "The highest performing deep learning model was actually the sequential model, which is the most simple implementation. It makes sense that it works better because this dataset is very simple and a very simple instance of classification. \n",
        "### RNN\n",
        "The SimpleRNN capped at 86.7% with no special embeddings. This was lower than the sequential model, but it is still high and it is able to reach this accuracy after very few epochs.\n",
        "### Embeddings\n",
        "I implemented GloVe embeddings, a powerful word embedding model. It actually reduced the SimpleRNN's learning capabilities, making it take more epochs in order to reach the same max accuracy. "
      ],
      "metadata": {
        "id": "SzpcoOQWMR0m"
      }
    }
  ]
}